{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\conda\\conda\\envs\\DSI-6\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%run imports_and_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Constructing All Cities Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>urban</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>blockgroup</th>\n",
       "      <th>income</th>\n",
       "      <th>blockgrouppop</th>\n",
       "      <th>population</th>\n",
       "      <th>landarea</th>\n",
       "      <th>waterarea</th>\n",
       "      <th>block</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320030029581005</th>\n",
       "      <td>5403.219921</td>\n",
       "      <td>U</td>\n",
       "      <td>36.093640</td>\n",
       "      <td>-115.241871</td>\n",
       "      <td>320030029581</td>\n",
       "      <td>25757</td>\n",
       "      <td>1495</td>\n",
       "      <td>155</td>\n",
       "      <td>54924</td>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030029572000</th>\n",
       "      <td>5808.613932</td>\n",
       "      <td>U</td>\n",
       "      <td>36.096091</td>\n",
       "      <td>-115.248927</td>\n",
       "      <td>320030029572</td>\n",
       "      <td>52256</td>\n",
       "      <td>884</td>\n",
       "      <td>437</td>\n",
       "      <td>728659</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030010042004</th>\n",
       "      <td>3855.731439</td>\n",
       "      <td>U</td>\n",
       "      <td>36.155052</td>\n",
       "      <td>-115.198804</td>\n",
       "      <td>320030010042</td>\n",
       "      <td>25408</td>\n",
       "      <td>1249</td>\n",
       "      <td>32</td>\n",
       "      <td>17103</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030010031016</th>\n",
       "      <td>4532.868829</td>\n",
       "      <td>U</td>\n",
       "      <td>36.154625</td>\n",
       "      <td>-115.220151</td>\n",
       "      <td>320030010031</td>\n",
       "      <td>24759</td>\n",
       "      <td>1058</td>\n",
       "      <td>29</td>\n",
       "      <td>41920</td>\n",
       "      <td>0</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030029381020</th>\n",
       "      <td>3136.357472</td>\n",
       "      <td>U</td>\n",
       "      <td>36.137785</td>\n",
       "      <td>-115.219814</td>\n",
       "      <td>320030029381</td>\n",
       "      <td>34314</td>\n",
       "      <td>1539</td>\n",
       "      <td>35</td>\n",
       "      <td>39561</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    distance urban   latitude   longitude    blockgroup  \\\n",
       "geoid                                                                     \n",
       "320030029581005  5403.219921     U  36.093640 -115.241871  320030029581   \n",
       "320030029572000  5808.613932     U  36.096091 -115.248927  320030029572   \n",
       "320030010042004  3855.731439     U  36.155052 -115.198804  320030010042   \n",
       "320030010031016  4532.868829     U  36.154625 -115.220151  320030010031   \n",
       "320030029381020  3136.357472     U  36.137785 -115.219814  320030029381   \n",
       "\n",
       "                 income  blockgrouppop  population  landarea  waterarea  block  \n",
       "geoid                                                                           \n",
       "320030029581005   25757           1495         155     54924          0   1005  \n",
       "320030029572000   52256            884         437    728659          0   2000  \n",
       "320030010042004   25408           1249          32     17103          0   2004  \n",
       "320030010031016   24759           1058          29     41920          0   1016  \n",
       "320030029381020   34314           1539          35     39561          0   1020  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainrowcoords = pd.read_csv('LasVegasTrainRowCoords.csv',sep=';',compression='gzip')\n",
    "trainrowcoords = trainrowcoords.set_index('Unnamed: 0')\n",
    "trainrowcoords.index.name = 'geoid'\n",
    "trainrowcoords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train = joblib.load('y_trainLasVegas.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1784,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1784, 1482)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load('X_trainLasVegas.joblib')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train2 = joblib.load('X_trainPhoenix.joblib')\n",
    "y_train2 = joblib.load('y_trainPhoenix.joblib')\n",
    "\n",
    "X_train3 = joblib.load('X_trainCharlotte.joblib')\n",
    "y_train3 = joblib.load('y_trainCharlotte.joblib')\n",
    "\n",
    "X_train4 = joblib.load('X_trainPittsburgh.joblib')\n",
    "y_train4 = joblib.load('y_trainPittsburgh.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1784, 1482) (3349, 1482) (2739, 1482) (3297, 1482)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_train2.shape, X_train3.shape, X_train4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_allcities = X_train.append(X_train2).append(X_train3).append(X_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11169,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_allcities = y_train.append(y_train2).append(y_train3).append(y_train4)\n",
    "y_allcities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landarea</th>\n",
       "      <th>waterarea</th>\n",
       "      <th>0_restaurants_near</th>\n",
       "      <th>0_restaurants_far</th>\n",
       "      <th>1_restaurants_near</th>\n",
       "      <th>1_restaurants_far</th>\n",
       "      <th>2_restaurants_near</th>\n",
       "      <th>2_restaurants_far</th>\n",
       "      <th>3_restaurants_near</th>\n",
       "      <th>3_restaurants_far</th>\n",
       "      <th>4_restaurants_near</th>\n",
       "      <th>4_restaurants_far</th>\n",
       "      <th>0_shopping_near</th>\n",
       "      <th>0_shopping_far</th>\n",
       "      <th>1_shopping_near</th>\n",
       "      <th>1_shopping_far</th>\n",
       "      <th>2_shopping_near</th>\n",
       "      <th>2_shopping_far</th>\n",
       "      <th>3_shopping_near</th>\n",
       "      <th>3_shopping_far</th>\n",
       "      <th>4_shopping_near</th>\n",
       "      <th>4_shopping_far</th>\n",
       "      <th>0_food_near</th>\n",
       "      <th>0_food_far</th>\n",
       "      <th>1_food_near</th>\n",
       "      <th>1_food_far</th>\n",
       "      <th>2_food_near</th>\n",
       "      <th>2_food_far</th>\n",
       "      <th>3_food_near</th>\n",
       "      <th>3_food_far</th>\n",
       "      <th>4_food_near</th>\n",
       "      <th>4_food_far</th>\n",
       "      <th>0_beautysvc_near</th>\n",
       "      <th>0_beautysvc_far</th>\n",
       "      <th>1_beautysvc_near</th>\n",
       "      <th>1_beautysvc_far</th>\n",
       "      <th>2_beautysvc_near</th>\n",
       "      <th>2_beautysvc_far</th>\n",
       "      <th>3_beautysvc_near</th>\n",
       "      <th>3_beautysvc_far</th>\n",
       "      <th>4_beautysvc_near</th>\n",
       "      <th>4_beautysvc_far</th>\n",
       "      <th>0_homeservices_near</th>\n",
       "      <th>0_homeservices_far</th>\n",
       "      <th>1_homeservices_near</th>\n",
       "      <th>...</th>\n",
       "      <th>2_hair_extensions_far</th>\n",
       "      <th>3_hair_extensions_near</th>\n",
       "      <th>3_hair_extensions_far</th>\n",
       "      <th>4_hair_extensions_near</th>\n",
       "      <th>4_hair_extensions_far</th>\n",
       "      <th>0_lawyers_near</th>\n",
       "      <th>0_lawyers_far</th>\n",
       "      <th>1_lawyers_near</th>\n",
       "      <th>1_lawyers_far</th>\n",
       "      <th>2_lawyers_near</th>\n",
       "      <th>2_lawyers_far</th>\n",
       "      <th>3_lawyers_near</th>\n",
       "      <th>3_lawyers_far</th>\n",
       "      <th>4_lawyers_near</th>\n",
       "      <th>4_lawyers_far</th>\n",
       "      <th>0_french_near</th>\n",
       "      <th>0_french_far</th>\n",
       "      <th>1_french_near</th>\n",
       "      <th>1_french_far</th>\n",
       "      <th>2_french_near</th>\n",
       "      <th>2_french_far</th>\n",
       "      <th>3_french_near</th>\n",
       "      <th>3_french_far</th>\n",
       "      <th>4_french_near</th>\n",
       "      <th>4_french_far</th>\n",
       "      <th>0_selfstorage_near</th>\n",
       "      <th>0_selfstorage_far</th>\n",
       "      <th>1_selfstorage_near</th>\n",
       "      <th>1_selfstorage_far</th>\n",
       "      <th>2_selfstorage_near</th>\n",
       "      <th>2_selfstorage_far</th>\n",
       "      <th>3_selfstorage_near</th>\n",
       "      <th>3_selfstorage_far</th>\n",
       "      <th>4_selfstorage_near</th>\n",
       "      <th>4_selfstorage_far</th>\n",
       "      <th>0_physicaltherapy_near</th>\n",
       "      <th>0_physicaltherapy_far</th>\n",
       "      <th>1_physicaltherapy_near</th>\n",
       "      <th>1_physicaltherapy_far</th>\n",
       "      <th>2_physicaltherapy_near</th>\n",
       "      <th>2_physicaltherapy_far</th>\n",
       "      <th>3_physicaltherapy_near</th>\n",
       "      <th>3_physicaltherapy_far</th>\n",
       "      <th>4_physicaltherapy_near</th>\n",
       "      <th>4_physicaltherapy_far</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320030029581005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030029572000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030010042004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030010031016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320030029381020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1482 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 landarea  waterarea  0_restaurants_near  0_restaurants_far  \\\n",
       "320030029581005         0          0                   0                  1   \n",
       "320030029572000         0          0                   0                  1   \n",
       "320030010042004         0          0                   0                  3   \n",
       "320030010031016         0          0                   0                  2   \n",
       "320030029381020         0          0                   0                 35   \n",
       "\n",
       "                 1_restaurants_near  1_restaurants_far  2_restaurants_near  \\\n",
       "320030029581005                   8                 37                   4   \n",
       "320030029572000                   0                 31                   0   \n",
       "320030010042004                   3                 22                   3   \n",
       "320030010031016                   0                 22                   1   \n",
       "320030029381020                   0                 71                   0   \n",
       "\n",
       "                 2_restaurants_far  3_restaurants_near  3_restaurants_far  \\\n",
       "320030029581005                 26                   0                  0   \n",
       "320030029572000                 22                   0                  0   \n",
       "320030010042004                 16                   0                  0   \n",
       "320030010031016                 12                   0                  8   \n",
       "320030029381020                 11                   0                  3   \n",
       "\n",
       "                 4_restaurants_near  4_restaurants_far  0_shopping_near  \\\n",
       "320030029581005                   0                  0                0   \n",
       "320030029572000                   0                  0                0   \n",
       "320030010042004                   0                  0                4   \n",
       "320030010031016                   0                  0                0   \n",
       "320030029381020                   0                  0                0   \n",
       "\n",
       "                 0_shopping_far  1_shopping_near  1_shopping_far  \\\n",
       "320030029581005               4                0              27   \n",
       "320030029572000               3                0              17   \n",
       "320030010042004              12                4              17   \n",
       "320030010031016              12                0              14   \n",
       "320030029381020              42                0               2   \n",
       "\n",
       "                 2_shopping_near  2_shopping_far  3_shopping_near  \\\n",
       "320030029581005                4               6                2   \n",
       "320030029572000                0               5                0   \n",
       "320030010042004               10              38                1   \n",
       "320030010031016                0              13                0   \n",
       "320030029381020                1              99                0   \n",
       "\n",
       "                 3_shopping_far  4_shopping_near  4_shopping_far  0_food_near  \\\n",
       "320030029581005               0                0               0            0   \n",
       "320030029572000               2                0               0            0   \n",
       "320030010042004               6                0               0            0   \n",
       "320030010031016               4                0               2            2   \n",
       "320030029381020               1                0               0            0   \n",
       "\n",
       "                 0_food_far  1_food_near  1_food_far  2_food_near  2_food_far  \\\n",
       "320030029581005           0            4          19            3           7   \n",
       "320030029572000           0            0           7            0           7   \n",
       "320030010042004           3            5          14            2           1   \n",
       "320030010031016           2            0           4            1          10   \n",
       "320030029381020          32            0         100            0          34   \n",
       "\n",
       "                 3_food_near  3_food_far  4_food_near  4_food_far  \\\n",
       "320030029581005            0           0            0           0   \n",
       "320030029572000            0           0            0           0   \n",
       "320030010042004            0           2            0           0   \n",
       "320030010031016            0           4            0           0   \n",
       "320030029381020            0           0            0           0   \n",
       "\n",
       "                 0_beautysvc_near  0_beautysvc_far  1_beautysvc_near  \\\n",
       "320030029581005                 0                2                 3   \n",
       "320030029572000                 0                2                 0   \n",
       "320030010042004                 0                4                 1   \n",
       "320030010031016                 0                3                 0   \n",
       "320030029381020                 0               94                 0   \n",
       "\n",
       "                 1_beautysvc_far  2_beautysvc_near  2_beautysvc_far  \\\n",
       "320030029581005               32                 5               16   \n",
       "320030029572000               30                 0                8   \n",
       "320030010042004                7                 1               15   \n",
       "320030010031016                6                 0               19   \n",
       "320030029381020               10                 4               47   \n",
       "\n",
       "                 3_beautysvc_near  3_beautysvc_far  4_beautysvc_near  \\\n",
       "320030029581005                 0                0                 0   \n",
       "320030029572000                 0                0                 0   \n",
       "320030010042004                 0                2                 0   \n",
       "320030010031016                 0                6                 0   \n",
       "320030029381020                 2                1                 0   \n",
       "\n",
       "                 4_beautysvc_far  0_homeservices_near  0_homeservices_far  \\\n",
       "320030029581005                0                    2                  14   \n",
       "320030029572000                0                    1                   7   \n",
       "320030010042004                0                    4                  39   \n",
       "320030010031016                0                    4                  16   \n",
       "320030029381020                0                   12                 309   \n",
       "\n",
       "                 1_homeservices_near          ...            \\\n",
       "320030029581005                    0          ...             \n",
       "320030029572000                    0          ...             \n",
       "320030010042004                    0          ...             \n",
       "320030010031016                    0          ...             \n",
       "320030029381020                    0          ...             \n",
       "\n",
       "                 2_hair_extensions_far  3_hair_extensions_near  \\\n",
       "320030029581005                      0                       0   \n",
       "320030029572000                      0                       0   \n",
       "320030010042004                      8                       0   \n",
       "320030010031016                      0                       0   \n",
       "320030029381020                      4                       0   \n",
       "\n",
       "                 3_hair_extensions_far  4_hair_extensions_near  \\\n",
       "320030029581005                      0                       0   \n",
       "320030029572000                      0                       0   \n",
       "320030010042004                      0                       0   \n",
       "320030010031016                      1                       0   \n",
       "320030029381020                      0                       0   \n",
       "\n",
       "                 4_hair_extensions_far  0_lawyers_near  0_lawyers_far  \\\n",
       "320030029581005                      0               0              1   \n",
       "320030029572000                      0               0              1   \n",
       "320030010042004                      0               0              2   \n",
       "320030010031016                      0               6              1   \n",
       "320030029381020                      0               1              5   \n",
       "\n",
       "                 1_lawyers_near  1_lawyers_far  2_lawyers_near  2_lawyers_far  \\\n",
       "320030029581005               0              0               0              0   \n",
       "320030029572000               0              0               0              0   \n",
       "320030010042004               0              0               0              0   \n",
       "320030010031016               0              0               0              0   \n",
       "320030029381020               0              0               0              0   \n",
       "\n",
       "                 3_lawyers_near  3_lawyers_far  4_lawyers_near  4_lawyers_far  \\\n",
       "320030029581005               0              0               0              0   \n",
       "320030029572000               0              0               0              0   \n",
       "320030010042004               0              0               0              0   \n",
       "320030010031016               0              0               0              0   \n",
       "320030029381020               0              0               0              0   \n",
       "\n",
       "                 0_french_near  0_french_far  1_french_near  1_french_far  \\\n",
       "320030029581005              0             0              0             3   \n",
       "320030029572000              0             0              0             0   \n",
       "320030010042004              0             0              0             0   \n",
       "320030010031016              0             0              0             0   \n",
       "320030029381020              0             0              0             0   \n",
       "\n",
       "                 2_french_near  2_french_far  3_french_near  3_french_far  \\\n",
       "320030029581005              0             0              0             0   \n",
       "320030029572000              0             0              0             0   \n",
       "320030010042004              0             0              0             0   \n",
       "320030010031016              0             0              0             0   \n",
       "320030029381020              0             0              0             0   \n",
       "\n",
       "                 4_french_near  4_french_far  0_selfstorage_near  \\\n",
       "320030029581005              0             0                   1   \n",
       "320030029572000              0             0                   0   \n",
       "320030010042004              0             0                   1   \n",
       "320030010031016              0             0                   1   \n",
       "320030029381020              0             0                   0   \n",
       "\n",
       "                 0_selfstorage_far  1_selfstorage_near  1_selfstorage_far  \\\n",
       "320030029581005                  1                   0                  0   \n",
       "320030029572000                  1                   0                  0   \n",
       "320030010042004                  1                   0                  0   \n",
       "320030010031016                  0                   0                  0   \n",
       "320030029381020                 31                   0                  0   \n",
       "\n",
       "                 2_selfstorage_near  2_selfstorage_far  3_selfstorage_near  \\\n",
       "320030029581005                   0                  0                   0   \n",
       "320030029572000                   0                  0                   0   \n",
       "320030010042004                   0                  0                   0   \n",
       "320030010031016                   0                  0                   0   \n",
       "320030029381020                   0                  0                   0   \n",
       "\n",
       "                 3_selfstorage_far  4_selfstorage_near  4_selfstorage_far  \\\n",
       "320030029581005                  0                   0                  0   \n",
       "320030029572000                  0                   0                  0   \n",
       "320030010042004                  0                   0                  0   \n",
       "320030010031016                  0                   0                  0   \n",
       "320030029381020                  0                   0                  0   \n",
       "\n",
       "                 0_physicaltherapy_near  0_physicaltherapy_far  \\\n",
       "320030029581005                       0                      0   \n",
       "320030029572000                       0                      0   \n",
       "320030010042004                       1                      3   \n",
       "320030010031016                       0                      3   \n",
       "320030029381020                       0                      3   \n",
       "\n",
       "                 1_physicaltherapy_near  1_physicaltherapy_far  \\\n",
       "320030029581005                       0                      0   \n",
       "320030029572000                       0                      0   \n",
       "320030010042004                       0                      0   \n",
       "320030010031016                       0                      0   \n",
       "320030029381020                       0                      0   \n",
       "\n",
       "                 2_physicaltherapy_near  2_physicaltherapy_far  \\\n",
       "320030029581005                       0                      0   \n",
       "320030029572000                       0                      0   \n",
       "320030010042004                       0                      0   \n",
       "320030010031016                       0                      0   \n",
       "320030029381020                       0                      0   \n",
       "\n",
       "                 3_physicaltherapy_near  3_physicaltherapy_far  \\\n",
       "320030029581005                       0                      0   \n",
       "320030029572000                       0                      0   \n",
       "320030010042004                       0                      0   \n",
       "320030010031016                       0                      0   \n",
       "320030029381020                       0                      0   \n",
       "\n",
       "                 4_physicaltherapy_near  4_physicaltherapy_far  \n",
       "320030029581005                       0                      0  \n",
       "320030029572000                       0                      0  \n",
       "320030010042004                       0                      0  \n",
       "320030010031016                       0                      0  \n",
       "320030029381020                       0                      0  \n",
       "\n",
       "[5 rows x 1482 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_allcities.index = y_allcities.index\n",
    "X_allcities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rowstodrop = y_allcities[y_allcities == '-'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11169, 1482)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11153, 1482)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_allcities.shape)\n",
    "X_allcities.drop(rowstodrop, axis=0, inplace=True)\n",
    "X_allcities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11169,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11153,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_allcities.shape)\n",
    "y_allcities.drop(rowstodrop, axis=0, inplace=True)\n",
    "y_allcities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11153, 1482)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11126, 1482)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nantodrop = y_allcities[y_allcities.isna()].index\n",
    "print(X_allcities.shape)\n",
    "X_allcities.drop(nantodrop, axis=0, inplace=True)\n",
    "X_allcities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11153,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11126,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_allcities.shape)\n",
    "y_allcities.drop(nantodrop, axis=0, inplace=True)\n",
    "y_allcities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320030029581005    25757.0\n",
       "320030029572000    52256.0\n",
       "320030010042004    25408.0\n",
       "320030010031016    24759.0\n",
       "320030029381020    34314.0\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_allcities = y_allcities.map(float)\n",
    "\n",
    "y_allcities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xtrain_allcities.joblib']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_allcities, 'Xtrain_allcities.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ytrain_allcities.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_allcities, 'ytrain_allcities.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Varied ML Models on All Cities Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, RandomForestRegressor, BaggingClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_allcities = joblib.load('Xtrain_allcities.joblib')\n",
    "y_allcities = joblib.load('ytrain_allcities.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_scorer(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_pred = pd.Series(data=model.predict(X_train),dtype=int)\n",
    "    accuracy_train = f1_score(y_true = y_train,\n",
    "                        y_pred = y_pred, average=None)\n",
    "    \n",
    "    y_pred = pd.Series(data=model.predict(X_test),dtype=int)\n",
    "    accuracy_test = f1_score(y_true = y_test,\n",
    "                       y_pred = y_pred, average=None)\n",
    "    \n",
    "    r2_scores = (model.score(X_train, y_train), model.score(X_test, y_test))\n",
    "    \n",
    "    print(\"R2 scores for \" + str(type(model)) + \" train set: \" + str(r2_scores[0]))\n",
    "    print(\"R2 scores for \" + str(type(model)) + \" test set: \" + str(r2_scores[1]))\n",
    "    print(\"The training accuracy-score for \" + str(type(model)) + \" is: \")\n",
    "    print(str(accuracy_train))\n",
    "    print(\"The testing accuracy-score for \" + str(type(model)) + \" is: \")\n",
    "    print(str(accuracy_test))\n",
    "    print()\n",
    "    return (accuracy_train, accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Preliminary Regressions (income still continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9457, 1482)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_allcities, y_allcities, \n",
    "                                                    test_size=.15, random_state=42) \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "## Applying PCA to Xs\n",
    "pca = PCA()\n",
    "pca = pca.fit(X_train_scaled)\n",
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test =pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear_reg_PCA = LinearRegression()\n",
    "linear_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "knn_reg_PCA = KNeighborsRegressor()\n",
    "knn_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "cart_reg_PCA = DecisionTreeRegressor()\n",
    "cart_reg_PCA.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagged_reg_PCA = BaggingRegressor()\n",
    "bagged_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_reg_PCA = AdaBoostRegressor()\n",
    "adaboost_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "random_forest_reg_PCA = RandomForestRegressor()\n",
    "random_forest_reg_PCA.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vector_reg_PCA = SVR()\n",
    "support_vector_reg_PCA.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca_reg_models = [linear_reg_PCA, knn_reg_PCA, cart_reg_PCA, bagged_reg_PCA, \n",
    "              adaboost_reg_PCA, random_forest_reg_PCA, support_vector_reg_PCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rmse_scorer(model, X_train, X_test, y_train, y_test):\n",
    "    mse_train = mean_squared_error(y_true = y_train,\n",
    "                                  y_pred = model.predict(X_train))\n",
    "    mse_test = mean_squared_error(y_true = y_test,\n",
    "                                  y_pred = model.predict(X_test))\n",
    "    rmse_train = mse_train ** 0.5\n",
    "    rmse_test = mse_test ** 0.5\n",
    "\n",
    "    r2_scores = (model.score(X_train, y_train), model.score(X_test, y_test))\n",
    "    \n",
    "    print(\"R2 scores for \" + str(type(model)) + \" train set: \" + str(r2_scores[0]))\n",
    "    print(\"R2 scores for \" + str(type(model)) + \" test set: \" + str(r2_scores[1]))\n",
    "    print(\"The training RMSE for \" + str(type(model)) + \" is: \")\n",
    "    print(str(rmse_train))\n",
    "    print(\"The testing RMSE for \" + str(type(model)) + \" is: \")\n",
    "    print(str(rmse_test))\n",
    "    print()\n",
    "    return (rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.base.LinearRegression'> train set: 0.7998428809318361\n",
      "R2 scores for <class 'sklearn.linear_model.base.LinearRegression'> test set: -2.1657883903251046e+23\n",
      "The training RMSE for <class 'sklearn.linear_model.base.LinearRegression'> is: \n",
      "10388.948010809852\n",
      "The testing RMSE for <class 'sklearn.linear_model.base.LinearRegression'> is: \n",
      "1.0169723572506662e+16\n",
      "\n",
      "R2 scores for <class 'sklearn.neighbors.regression.KNeighborsRegressor'> train set: 0.8791982969879253\n",
      "R2 scores for <class 'sklearn.neighbors.regression.KNeighborsRegressor'> test set: 0.8440173262915125\n",
      "The training RMSE for <class 'sklearn.neighbors.regression.KNeighborsRegressor'> is: \n",
      "8070.911415906978\n",
      "The testing RMSE for <class 'sklearn.neighbors.regression.KNeighborsRegressor'> is: \n",
      "8630.56679047727\n",
      "\n",
      "R2 scores for <class 'sklearn.tree.tree.DecisionTreeRegressor'> train set: 0.9621831940443599\n",
      "R2 scores for <class 'sklearn.tree.tree.DecisionTreeRegressor'> test set: 0.5686861683209876\n",
      "The training RMSE for <class 'sklearn.tree.tree.DecisionTreeRegressor'> is: \n",
      "4515.73527852918\n",
      "The testing RMSE for <class 'sklearn.tree.tree.DecisionTreeRegressor'> is: \n",
      "14351.517684339731\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingRegressor'> train set: 0.9191200532146927\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingRegressor'> test set: 0.752736901789519\n",
      "The training RMSE for <class 'sklearn.ensemble.bagging.BaggingRegressor'> is: \n",
      "6603.991120347733\n",
      "The testing RMSE for <class 'sklearn.ensemble.bagging.BaggingRegressor'> is: \n",
      "10866.277481579342\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> train set: 0.05340150137676403\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> test set: -0.1449784400818257\n",
      "The training RMSE for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> is: \n",
      "22592.742780130586\n",
      "The testing RMSE for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> is: \n",
      "23382.976444702625\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestRegressor'> train set: 0.9201575279059268\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestRegressor'> test set: 0.7601136174977673\n",
      "The training RMSE for <class 'sklearn.ensemble.forest.RandomForestRegressor'> is: \n",
      "6561.49858957903\n",
      "The testing RMSE for <class 'sklearn.ensemble.forest.RandomForestRegressor'> is: \n",
      "10702.960812648165\n",
      "\n",
      "R2 scores for <class 'sklearn.svm.classes.SVR'> train set: -0.02468720492470089\n",
      "R2 scores for <class 'sklearn.svm.classes.SVR'> test set: -0.015511679831556657\n",
      "The training RMSE for <class 'sklearn.svm.classes.SVR'> is: \n",
      "23506.161132134373\n",
      "The testing RMSE for <class 'sklearn.svm.classes.SVR'> is: \n",
      "22021.332737180426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in pca_reg_models :\n",
    "    rmse_scorer(model, Z_train, Z_test, y_train, y_test)\n",
    "# KNN has good scores but takes orders of magnitude time longer (10+ minutes) so shouldn't\n",
    "# implement for user side functionality\n",
    "# SVM is also pretty long, and has the worst scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing better models with PCA number of columns set to best 200 (out of 1482)\n",
    "bagged_reg_PCA = BaggingRegressor()\n",
    "bagged_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_reg_PCA = AdaBoostRegressor()\n",
    "adaboost_reg_PCA.fit(Z_train, y_train)\n",
    "\n",
    "random_forest_reg_PCA = RandomForestRegressor()\n",
    "random_forest_reg_PCA.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingRegressor'> train set: 0.931418388037298\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingRegressor'> test set: 0.7596213917622368\n",
      "The training RMSE for <class 'sklearn.ensemble.bagging.BaggingRegressor'> is: \n",
      "0.24040429478189504\n",
      "The testing RMSE for <class 'sklearn.ensemble.bagging.BaggingRegressor'> is: \n",
      "0.4284549107959935\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> train set: 0.3431086962397566\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> test set: 0.29172781641549006\n",
      "The training RMSE for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> is: \n",
      "0.7440208975927295\n",
      "The testing RMSE for <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> is: \n",
      "0.7354570402582684\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestRegressor'> train set: 0.9305483221778924\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestRegressor'> test set: 0.7683522078330332\n",
      "The training RMSE for <class 'sklearn.ensemble.forest.RandomForestRegressor'> is: \n",
      "0.24192444233592758\n",
      "The testing RMSE for <class 'sklearn.ensemble.forest.RandomForestRegressor'> is: \n",
      "0.4206019670153405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [bagged_reg_PCA, adaboost_reg_PCA, random_forest_reg_PCA] :\n",
    "    rmse_scorer(model, Z_train, Z_test, y_train, y_test)\n",
    "# restricting to top 200 variables of PCA axis rotation only improves r2 scores by about 1 percent here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 7 brackets of Income (0-11k, 11-21k, 21-31k, 31-41k, 41-51k, 51k-61k, 61k+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3655,)\n",
      "(2385,)\n",
      "(2164,)\n",
      "(1067,)\n",
      "(641,)\n",
      "(419,)\n",
      "(795,)\n"
     ]
    }
   ],
   "source": [
    "print(y_allcities[y_allcities < 11000].shape)\n",
    "print(y_allcities[(y_allcities >= 11000) & (y_allcities < 21000)].shape)\n",
    "print(y_allcities[(y_allcities >= 21000) & (y_allcities < 31000)].shape)\n",
    "print(y_allcities[(y_allcities >= 31000) & (y_allcities < 41000)].shape)\n",
    "print(y_allcities[(y_allcities >= 41000) & (y_allcities < 51000)].shape)\n",
    "print(y_allcities[(y_allcities >= 51000) & (y_allcities < 61000)].shape)\n",
    "print(y_allcities[y_allcities >= 61000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating column y_train_class\n",
    "\n",
    "y_train = y_allcities\n",
    "\n",
    "y_train_class = pd.Series(['NaN' for i in range(len(y_train)) ])\n",
    "\n",
    "## Creating y_train for classification\n",
    "\n",
    "brackets ={'$0-$10.99k': 0,'$11-$20.99k':1, '$21-$30.99k':2, '$31-$40.99k':3, '$41-$50.99k':54, \n",
    "           '$51-$60.99k':5,'$61-$70.99k':6, '$71+k':7}\n",
    "\n",
    "for index, value in enumerate(y_train):\n",
    "    if y_train.iloc[index] < 11000:\n",
    "        y_train_class.iloc[index] = brackets['$0-$10.99k']\n",
    "    elif y_train.iloc[index] < 21000:\n",
    "        y_train_class.iloc[index] = brackets['$11-$20.99k']\n",
    "    elif y_train.iloc[index] < 31000:\n",
    "        y_train_class.iloc[index] = brackets['$21-$30.99k']\n",
    "    elif y_train.iloc[index] < 41000:\n",
    "        y_train_class.iloc[index] = brackets['$31-$40.99k']   \n",
    "    elif y_train.iloc[index] < 51000:\n",
    "        y_train_class.iloc[index] = brackets['$41-$50.99k']\n",
    "    elif y_train.iloc[index] < 61000:\n",
    "        y_train_class.iloc[index] = brackets['$51-$60.99k']\n",
    "    elif y_train.iloc[index] < 71000:\n",
    "        y_train_class.iloc[index] = brackets['$61-$70.99k']   \n",
    "    elif y_train.iloc[index] >= 71000:\n",
    "        y_train_class.iloc[index] = brackets['$71+k']\n",
    "    else:\n",
    "        y_train_class.iloc[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9457, 1482)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_allcities, y_train_class, \n",
    "                                                    test_size=.15, random_state=42) \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic and Random Forest without PCA to get Theoretical Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(X_train, y_train)\n",
    "\n",
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.8132600190335202\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.7717195925704015\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.92312661 0.76304156 0.71416781 0.63925729 0.90576653 0.94033413\n",
      " 0.89384289 0.78738555]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.91620112 0.71658986 0.68661417 0.56818182 0.84126984 0.69090909\n",
      " 0.765625   0.75531915]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9556941947763561\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.8466147393648892\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.96927651 0.9094236  0.9557423  0.96645821 0.99152542 0.99530516\n",
      " 0.98031088 0.98867925]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.93433396 0.82352941 0.80781759 0.76190476 0.76923077 0.69387755\n",
      " 0.80314961 0.83333333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, random_forest_class_pca] :\n",
    "    accuracy_scorer(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_No_pca_8brackets_1stcities.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(logreg_class_pca, 'log_No_pca_8brackets_1stcities.joblib', compress=9)\n",
    "\n",
    "joblib.dump(random_forest_class_pca, 'rf_No_pca_8brackets_1stcities.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logreg_class_pca.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00210959, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_class_pca.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "## Applying PCA to Xs\n",
    "pca = PCA(n_components=200)\n",
    "pca = pca.fit(X_train_scaled)\n",
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test =pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_class_pca = KNeighborsClassifier()\n",
    "knn_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_class_pca = DecisionTreeClassifier()\n",
    "cart_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "bagged_class_pca = BaggingClassifier()\n",
    "bagged_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_class_pca = AdaBoostClassifier()\n",
    "adaboost_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# support_vector_class_pca = SVC()\n",
    "# support_vector_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.9050438828381093\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.8376273217495507\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: [0.96134787 0.84821429 0.86104149 0.87700535 0.94524496 0.95421687\n",
      " 0.95010395 0.93140097]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: [0.9417383  0.82420091 0.78373984 0.70588235 0.816      0.79245283\n",
      " 0.79069767 0.76470588]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9548482605477424\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.7681246255242661\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: [0.96831683 0.90838474 0.95457095 0.96587031 0.99004267 0.99297424\n",
      " 0.98343685 0.98770104]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: [0.88808007 0.76334107 0.74339036 0.61090909 0.60869565 0.46511628\n",
      " 0.61403509 0.6631016 ]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> train set: 0.44675901448662364\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> test set: 0.4343918514080288\n",
      "The training accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: [0.64278579 0.43084877 0.29865067 0.10838273 0.31139647 0.36641221\n",
      " 0.37263158 0.1660281 ]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: [0.60720131 0.46823529 0.29301533 0.08737864 0.31775701 0.22857143\n",
      " 0.30534351 0.18181818]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, random_forest_class_pca, adaboost_class_pca] :\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)\n",
    "# AdaBoost is the worst classifier among those tested, with default parameters, and\n",
    "# with this level of income brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(logreg_class_pca, 'log_pca_8brackets.joblib', compress=9)\n",
    "\n",
    "joblib.dump(random_forest_class_pca, 'rf_pca_8brackets.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.tree.tree.DecisionTreeClassifier'> train set: 0.9579147721264671\n",
      "R2 scores for <class 'sklearn.tree.tree.DecisionTreeClassifier'> test set: 0.6878370281605752\n",
      "The training accuracy-score for <class 'sklearn.tree.tree.DecisionTreeClassifier'> is: [0.96959683 0.91054679 0.95908072 0.97107204 0.99575672 0.99765808\n",
      " 0.98655636 0.99338999]\n",
      "The testing accuracy-score for <class 'sklearn.tree.tree.DecisionTreeClassifier'> is: [0.8213228  0.71544715 0.67298578 0.53896104 0.453125   0.2962963\n",
      " 0.47058824 0.57560976]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.9532621338690916\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.7902935889754344\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: [0.96815707 0.90830094 0.95328671 0.96177981 0.98011364 0.9882904\n",
      " 0.9761163  0.98676749]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: [0.89171975 0.79171461 0.76898223 0.65964912 0.66071429 0.5\n",
      " 0.6446281  0.6984127 ]\n",
      "\n",
      "R2 scores for <class 'sklearn.svm.classes.SVC'> train set: 0.7573226181664375\n",
      "R2 scores for <class 'sklearn.svm.classes.SVC'> test set: 0.7309766327142001\n",
      "The training accuracy-score for <class 'sklearn.svm.classes.SVC'> is: [0.89884722 0.70781734 0.67110036 0.59756098 0.65551839 0.73537604\n",
      " 0.77312775 0.71428571]\n",
      "The testing accuracy-score for <class 'sklearn.svm.classes.SVC'> is: [0.89538172 0.70612245 0.61672474 0.54615385 0.58490566 0.65217391\n",
      " 0.70967742 0.65240642]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [cart_class_pca, bagged_class_pca, support_vector_class_pca] :\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)\n",
    "# SVC is not that good, scoring wise and takes orders of magnitude more time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> train set: 0.848260547742413\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> test set: 0.7890952666267226\n",
      "The training accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.90238548 0.80592105 0.84248475 0.77426901 0.80225989 0.8\n",
      " 0.86508754 0.81695568]\n",
      "The testing accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.88519135 0.73537604 0.75974026 0.67114094 0.72440945 0.73076923\n",
      " 0.8125     0.7106599 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.90238548, 0.80592105, 0.84248475, 0.77426901, 0.80225989,\n",
       "        0.8       , 0.86508754, 0.81695568]),\n",
       " array([0.88519135, 0.73537604, 0.75974026, 0.67114094, 0.72440945,\n",
       "        0.73076923, 0.8125    , 0.7106599 ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scorer(knn_class_pca, Z_train, Z_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 4 brackets of Income (0-20k, 20-40k, 40k-60k, 61k+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774,)\n",
      "(3448,)\n",
      "(1080,)\n",
      "(824,)\n"
     ]
    }
   ],
   "source": [
    "print(y_allcities[y_allcities < 20000].shape)\n",
    "print(y_allcities[(y_allcities >= 20000) & (y_allcities < 40000)].shape)\n",
    "print(y_allcities[(y_allcities >= 40000) & (y_allcities < 60000)].shape)\n",
    "print(y_allcities[y_allcities >= 60000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating column y_train_class2\n",
    "\n",
    "y_train = y_allcities\n",
    "\n",
    "y_train_class2 = pd.Series(['NaN' for i in range(len(y_train)) ])\n",
    "\n",
    "## Creating y_train for classification\n",
    "\n",
    "brackets ={'$0-$20.99k': 0,'$21-$40.99k':1, '$41-$60.99k':2, '$61+k':3}\n",
    "\n",
    "for index, value in enumerate(y_train):\n",
    "    if y_train.iloc[index] < 21000:\n",
    "        y_train_class2.iloc[index] = brackets['$0-$20.99k']\n",
    "    elif y_train.iloc[index] < 41000:\n",
    "        y_train_class2.iloc[index] = brackets['$21-$40.99k']\n",
    "    elif y_train.iloc[index] < 61000:\n",
    "        y_train_class2.iloc[index] = brackets['$41-$60.99k']\n",
    "    elif y_train.iloc[index] >= 61000:\n",
    "        y_train_class2.iloc[index] = brackets['$61+k']\n",
    "    else:\n",
    "        y_train_class2.iloc[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9457, 1482)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_allcities, y_train_class2, \n",
    "                                                    test_size=.15, random_state=42) \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(X_train, y_train)\n",
    "\n",
    "knn_class_pca = KNeighborsClassifier()\n",
    "knn_class_pca.fit(X_train, y_train)\n",
    "\n",
    "bagged_class_pca = BaggingClassifier()\n",
    "bagged_class_pca.fit(X_train, y_train)\n",
    "\n",
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.8822036586655387\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.8478130617136009\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.92168562 0.81661562 0.81957187 0.89841986]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.90309278 0.76600442 0.76677316 0.80446927]\n",
      "\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> train set: 0.9140319340171301\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> test set: 0.8753744757339724\n",
      "The training accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.9462201  0.8764255  0.85353245 0.8922853 ]\n",
      "The testing accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.92864638 0.82034632 0.77675841 0.77348066]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.974727714920165\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.89035350509287\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.97786296 0.96097561 0.9875     0.98776098]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.93333333 0.84439608 0.81846154 0.79310345]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.975044940255895\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.895745955662073\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.97825046 0.96073643 0.98866213 0.98848921]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.93862816 0.85524862 0.80124224 0.80232558]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, knn_class_pca, bagged_class_pca, random_forest_class_pca] :\n",
    "    accuracy_scorer(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_allcities.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_No_pca_4brackets_1stcities.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_allcities.sum(), '1stcities_category_counts.joblib', compress=9)\n",
    "\n",
    "joblib.dump(logreg_class_pca, 'log_No_pca_4brackets_1stcities.joblib', compress=9)\n",
    "\n",
    "joblib.dump(random_forest_class_pca, 'rf_No_pca_4brackets_1stcities.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9457, 1482)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "## Applying PCA to Xs\n",
    "pca = PCA(n_components=200)\n",
    "pca = pca.fit(X_train_scaled)\n",
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test =pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-501b600535cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogreg_class_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogreg_class_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mknn_class_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mknn_class_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Z_train' is not defined"
     ]
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "knn_class_pca = KNeighborsClassifier()\n",
    "knn_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "bagged_class_pca = BaggingClassifier()\n",
    "bagged_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_class_pca = AdaBoostClassifier()\n",
    "adaboost_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.7387120651369357\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.7243858597962852\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.82445657 0.55809935 0.61528059 0.76152623]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.82415459 0.5403423  0.56115108 0.6627907 ]\n",
      "\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> train set: 0.9078989108596807\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> test set: 0.8669862192929898\n",
      "The training accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.94235925 0.86964688 0.83966006 0.88196959]\n",
      "The testing accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.91920252 0.79694323 0.80239521 0.79120879]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.9741990060272814\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.8801677651288197\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.97815255 0.95909944 0.98864926 0.98412698]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.92567914 0.828125   0.8136646  0.75739645]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9726128793486306\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.8759736369083283\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.97671745 0.9576303  0.9857712  0.98268398]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.92584964 0.81758242 0.77564103 0.8045977 ]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> train set: 0.6462937506608861\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> test set: 0.6440982624325944\n",
      "The training accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.7643128  0.46603848 0.42445055 0.59534884]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.76915423 0.44700461 0.40875912 0.55913978]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, knn_class_pca, bagged_class_pca, random_forest_class_pca, \n",
    "              adaboost_class_pca] :\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 3 brackets of Income (0-30k, 30k-60k, 61k+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8120,)\n",
      "(2182,)\n",
      "(824,)\n"
     ]
    }
   ],
   "source": [
    "print(y_allcities[y_allcities < 30000].shape)\n",
    "print(y_allcities[(y_allcities >= 30000) & (y_allcities < 60000)].shape)\n",
    "print(y_allcities[y_allcities >= 60000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating column y_train_class3\n",
    "\n",
    "y_train = y_allcities\n",
    "\n",
    "y_train_class3 = pd.Series(['NaN' for i in range(len(y_train)) ])\n",
    "\n",
    "## Creating y_train for classification\n",
    "\n",
    "brackets ={'$0-$30.99k': 0,'$31-$60.99k':1, '$61+k':3}\n",
    "\n",
    "for index, value in enumerate(y_train):\n",
    "    if y_train.iloc[index] < 31000:\n",
    "        y_train_class3.iloc[index] = brackets['$0-$30.99k']\n",
    "    elif y_train.iloc[index] < 61000:\n",
    "        y_train_class3.iloc[index] = brackets['$31-$60.99k']\n",
    "    elif y_train.iloc[index] >= 61000:\n",
    "        y_train_class3.iloc[index] = brackets['$61+k']\n",
    "    else:\n",
    "        y_train_class3.iloc[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also with stratifying on income\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_allcities, y_train_class3, \n",
    "                                                    test_size=.15, random_state=42,\n",
    "                                                   stratify=y_train_class3) \n",
    "X_train.shape\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "## Applying PCA to Xs\n",
    "pca = PCA(n_components=200)\n",
    "pca = pca.fit(X_train_scaled)\n",
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test =pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "# knn_class_pca = KNeighborsClassifier()\n",
    "# knn_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "bagged_class_pca = BaggingClassifier()\n",
    "bagged_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_class_pca = AdaBoostClassifier()\n",
    "adaboost_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.8705720630221\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.8579988016776513\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.92443411 0.65917843 0.76085106]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.92110377 0.62611807 0.69902913]\n",
      "\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> train set: 0.9405731204398858\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> test set: 0.9185140802875974\n",
      "The training accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.9671062  0.85779685 0.87585682]\n",
      "The testing accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: \n",
      "[0.95683453 0.7960199  0.82403433]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.9870995030136407\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.9227082085080887\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.99181553 0.97053824 0.98124531]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.95971564 0.79310345 0.84070796]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9878396954636777\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.9155182744158179\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.99237729 0.97263752 0.98048048]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.95279308 0.7848537  0.82790698]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> train set: 0.8107222163476789\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> test set: 0.8034751348112642\n",
      "The training accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.89539523 0.44963905 0.64473684]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.89697434 0.41960784 0.58064516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, knn_class_pca, bagged_class_pca, random_forest_class_pca, \n",
    "              adaboost_class_pca] :\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.8701490959077932\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.8609946075494308\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.9247062  0.65199094 0.76534903]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: \n",
      "[0.92229992 0.63176895 0.71428571]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.9874167283493709\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.9197124026363092\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.99181436 0.97171946 0.98269375]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: \n",
      "[0.95689996 0.78974359 0.83928571]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9885798879137148\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.9149191132414619\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.99259154 0.97547223 0.98118886]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: \n",
      "[0.95518868 0.76625659 0.83555556]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> train set: 0.8128370519192133\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> test set: 0.811264230077891\n",
      "The training accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.89378432 0.47609562 0.6562228 ]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: \n",
      "[0.89819439 0.45977011 0.61032864]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, bagged_class_pca, random_forest_class_pca, \n",
    "              adaboost_class_pca] : # knn_class_pca\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)\n",
    "# with f1_score set to average=samples instead of None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.naive_bayes.MultinomialNB'> train set: 0.6291635825314582\n",
      "R2 scores for <class 'sklearn.naive_bayes.MultinomialNB'> test set: 0.609946075494308\n",
      "The training accuracy-score for <class 'sklearn.naive_bayes.MultinomialNB'> is: \n",
      "0.5476778755617402\n",
      "The testing accuracy-score for <class 'sklearn.naive_bayes.MultinomialNB'> is: \n",
      "0.5188460381031467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naivebayes_pca = MultinomialNB()\n",
    "naivebayes_pca.fit(X_train, y_train)\n",
    "accuracy_scorer(naivebayes_pca, X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6967    5    1]\n",
      " [  78 1730    0]\n",
      " [  20    4  652]]\n",
      "\n",
      "[[1215   15    1]\n",
      " [  90  218   11]\n",
      " [   8   17   94]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = random_forest_class_pca.predict(Z_train)\n",
    "print(confusion_matrix(y_train, y_pred_rf))\n",
    "print()\n",
    "y_pred_rf = random_forest_class_pca.predict(Z_test)\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6967    6    0]\n",
      " [  90 1718    0]\n",
      " [  19    4  653]]\n",
      "\n",
      "[[1210   20    1]\n",
      " [  78  231   10]\n",
      " [  10   15   94]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_bag = bagged_class_pca.predict(Z_train)\n",
    "print(confusion_matrix(y_train, y_pred_bag))\n",
    "print()\n",
    "y_pred_bag = bagged_class_pca.predict(Z_test)\n",
    "print(confusion_matrix(y_test, y_pred_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 3 brackets of Income (0-20k, 20k-50k, 51k+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774,)\n",
      "(4101,)\n",
      "(1251,)\n"
     ]
    }
   ],
   "source": [
    "print(y_allcities[y_allcities < 20000].shape)\n",
    "print(y_allcities[(y_allcities >= 20000) & (y_allcities < 50000)].shape)\n",
    "print(y_allcities[y_allcities >= 50000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating column y_train_class3\n",
    "\n",
    "y_train = y_allcities\n",
    "\n",
    "y_train_class3 = pd.Series(['NaN' for i in range(len(y_train)) ])\n",
    "\n",
    "## Creating y_train for classification\n",
    "\n",
    "brackets ={'$0-$20k': 0,'$20-$50k':1, '$50+k':3}\n",
    "\n",
    "for index, value in enumerate(y_train):\n",
    "    if y_train.iloc[index] < 20000:\n",
    "        y_train_class3.iloc[index] = brackets['$0-$20k']\n",
    "    elif y_train.iloc[index] < 50000:\n",
    "        y_train_class3.iloc[index] = brackets['$20-$50k']\n",
    "    elif y_train.iloc[index] >= 50000:\n",
    "        y_train_class3.iloc[index] = brackets['$50+k']\n",
    "    else:\n",
    "        y_train_class3.iloc[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also with stratifying on income\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_allcities, y_train_class3, \n",
    "                                                    test_size=.15, random_state=42,\n",
    "                                                   stratify=y_train_class3) \n",
    "X_train.shape\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "## Applying PCA to Xs\n",
    "pca = PCA(n_components=200)\n",
    "pca = pca.fit(X_train_scaled)\n",
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test =pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_class_pca = LogisticRegression()\n",
    "logreg_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "knn_class_pca = KNeighborsClassifier()\n",
    "knn_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "bagged_class_pca = BaggingClassifier()\n",
    "bagged_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "adaboost_class_pca = AdaBoostClassifier()\n",
    "adaboost_class_pca.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[833,  29,   4],\n",
       "       [100, 506,   9],\n",
       "       [ 19,  23, 146]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_class_pca = RandomForestClassifier()\n",
    "random_forest_class_pca.fit(Z_train, y_train)\n",
    "\n",
    "y_pred_rf = random_forest_class_pca.predict(Z_test)\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> train set: 0.7758274294173628\n",
      "R2 scores for <class 'sklearn.linear_model.logistic.LogisticRegression'> test set: 0.7495506291192331\n",
      "The training accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: [0.83234531 0.68824749 0.7428262 ]\n",
      "The testing accuracy-score for <class 'sklearn.linear_model.logistic.LogisticRegression'> is: [0.81837161 0.64845173 0.68518519]\n",
      "\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> train set: 0.9212223749603469\n",
      "R2 scores for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> test set: 0.89035350509287\n",
      "The training accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: [0.9429083  0.8993943  0.88761358]\n",
      "The testing accuracy-score for <class 'sklearn.neighbors.classification.KNeighborsClassifier'> is: [0.92359551 0.86218487 0.82065217]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> train set: 0.9722956540129005\n",
      "R2 scores for <class 'sklearn.ensemble.bagging.BaggingClassifier'> test set: 0.8921509886159377\n",
      "The training accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: [0.97531356 0.96379489 0.98524512]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.bagging.BaggingClassifier'> is: [0.92238973 0.86048454 0.84571429]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> train set: 0.9724013957914772\n",
      "R2 scores for <class 'sklearn.ensemble.forest.RandomForestClassifier'> test set: 0.8849610545236669\n",
      "The training accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: [0.97522142 0.96375203 0.98670465]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.forest.RandomForestClassifier'> is: [0.91712707 0.85593934 0.81524927]\n",
      "\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> train set: 0.6865813682986148\n",
      "R2 scores for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> test set: 0.6866387058118634\n",
      "The training accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: [0.77332054 0.57893166 0.58482143]\n",
      "The testing accuracy-score for <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is: [0.77902622 0.5771578  0.54037267]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [logreg_class_pca, knn_class_pca, bagged_class_pca, random_forest_class_pca, \n",
    "              adaboost_class_pca] :\n",
    "    accuracy_scorer(model, Z_train, Z_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_pca_0-20k-50k+.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn_class_pca, 'knn_pca_0-20k-50k+.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(random_forest_class_pca, 'rf_pca_0-20k-50k+.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(logreg_class_pca, 'log_pca_0-20k-50k+.joblib', compress=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
